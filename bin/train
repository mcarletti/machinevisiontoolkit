#!/usr/bin/env -S python -B

import argparse, os, pickle

import cv2, tqdm, torch
import torch.utils.data
import torchinfo

import mvt.utils
import mvt.metrics
import mvt.datasets
import mvt.nn.models
import mvt.nn.losses
import mvt.nn.optimizers
import mvt.nn.callbacks


def main(args):

    distributed, world_size, rank_global, rank_local = mvt.utils.init_distributed_mode(args)
    mvt.utils.set_reproducibility(args.seed + mvt.utils.get_rank(), {}, False)

    # aux variables
    if distributed:
        device = torch.device("cuda", rank_local)
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu") if args.device == "auto" else torch.device(args.device)
    input_shape = mvt.utils.string_to_shape(args.input_shape)

    # ===============
    # create datasets
    # ===============

    def transform(image, label, target_shape=input_shape[1:]):
        image = cv2.resize(image, target_shape)
        image = (image / 255 - 0.5).astype("float32")
        image = image.transpose(2, 0, 1)
        return image, label

    dataset_train = mvt.datasets.get_dataset(args.dataset_name, args.dataset_root, "train", args.dataset_task, transform)
    dataset_val = mvt.datasets.get_dataset(args.dataset_name, args.dataset_root, "val", args.dataset_task, transform)

    sampler_train = None
    sampler_val = None
    if distributed:
        sampler_train = torch.utils.data.DistributedSampler(dataset_train, num_replicas=world_size, rank=rank_global, shuffle=True, seed=args.seed)
        sampler_val = torch.utils.data.SequentialSampler(dataset_val)  # validation set is not distributed

    print(f"Train dataset: {len(dataset_train)} samples")
    print(f"Val dataset: {len(dataset_val)} samples")

    assert hasattr(dataset_train, "num_classes") and hasattr(dataset_val, "num_classes"), "Dataset must have an attribute 'num_classes'"
    assert dataset_train.num_classes == dataset_val.num_classes, "Train and val datasets must have the same number of classes"
    num_classes = dataset_train.num_classes

    # create dataloaders
    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, sampler=sampler_train)
    dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, sampler=sampler_val)

    # ============
    # create model
    # ============

    model = mvt.nn.models.get_model(args.model_name, input_shape, num_classes, args.checkpoint)
    model = model.to(device)

    torchinfo.summary(model, input_size=(1, *input_shape))

    if distributed:
        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[rank_global])

    # =============
    # prepare train
    # =============

    loss_fn   = mvt.nn.losses.get_loss(args.loss)
    optimizer = mvt.nn.optimizers.get_optimizers(args.optimizer, model, args.lr)
    metric_fn = mvt.metrics.accuracy_from_logits if args.dataset_task == "classification" else None

    # ===========
    # start train
    # ===========

    logger_cb = mvt.nn.callbacks.Logger(args.output)

    enable_amp = (device.type == "cuda")  # automatic mixed precision
    scaler = torch.cuda.amp.GradScaler(enabled=enable_amp)

    best_metric = 0

    for epoch in range(args.epochs):

        print(f"Epoch {epoch + 1}/{args.epochs}")

        # ----------
        # train step
        # ----------

        # aux variables
        metric = 0
        logs = {}

        if distributed:
            dataloader_train.sampler.set_epoch(epoch)

        model.train()
        for images, labels in tqdm.tqdm(dataloader_train):
            # prepare data
            images = images.to(device)
            labels = labels.to(device)
            # forward pass and loss computation
            with torch.cuda.amp.autocast(enable_amp):
                outputs = model(images)
                loss = loss_fn(outputs, labels)
            # backward pass
            optimizer.zero_grad()
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            # compute metrics
            metric += metric_fn(outputs, labels) / len(dataloader_train)

        print("Train metric: {:.4f}".format(metric))

        # update logs
        logs.update({"train/loss": loss.to("cpu").item()})
        logs.update({"train/metric": metric})

        # ---------------
        # validation step
        # ---------------

        # aux variables
        metric = 0

        model.eval()
        with torch.no_grad():
            for images, labels in dataloader_val:
                # prepare data
                images = images.to(device)
                labels = labels.to(device)
                # forward pass
                outputs = model(images)
                # compute loss
                loss = loss_fn(outputs, labels)
                # compute metrics
                metric += metric_fn(outputs, labels) / len(dataloader_val)

            print("Val metric:   {:.4f}".format(metric))

        # update logs
        logs.update({"val/loss": loss.to("cpu").item()})
        logs.update({"val/metric": metric})

        # ----
        # save
        # ----

        # create output folder
        os.makedirs(args.output, exist_ok=True)

        # tensorboard logs
        logger_cb(logs, epoch)

        # save last model
        torch.save(model.state_dict(), os.path.join(args.output, "last.pt"))

        # save last rng state
        rng_state = mvt.utils.get_rng_state()
        with open(os.path.join(args.output, "last_rng_state.pickle"), "wb") as f:
            pickle.dump(rng_state, f)

        # save best model and best rng state
        if metric >= best_metric:
            best_metric = metric
            torch.save(model.state_dict(), os.path.join(args.output, "best.pt"))
            print("Model saved at epoch {}".format(epoch + 1))

            with open(os.path.join(args.output, "best_rng_state.pickle"), "wb") as f:
                pickle.dump(rng_state, f)

    if distributed:
        torch.distributed.destroy_process_group()


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    # model
    parser.add_argument("--model_name",   type=str,   default="resnet18")
    parser.add_argument("--input_shape",  type=str,   default="3x32x32")
    parser.add_argument("--checkpoint",   type=str,   default=None)
    # dataset
    parser.add_argument("--dataset_root", type=str,   default="datasets")
    parser.add_argument("--dataset_name", type=str,   default="cifar10")
    parser.add_argument("--dataset_task", type=str,   default="classification", choices=["classification", "detection"])
    # training
    parser.add_argument("--loss",         type=str,   default="categorical_cross_entropy")
    parser.add_argument("--epochs",       type=int,   default=10)
    parser.add_argument("--batch_size",   type=int,   default=128)
    parser.add_argument("--optimizer",    type=str,   default="sgd", choices=["sgd", "adam"])
    parser.add_argument("--lr",           type=float, default=1e-2)
    parser.add_argument("--output",       type=str,   required=True)
    # misc
    parser.add_argument("--seed",         type=int,   default=0)
    parser.add_argument("--workers",      type=int,   default=2)
    parser.add_argument("--device",       type=str,   default="auto", choices=["cpu", "cuda", "auto"])

    args = parser.parse_args()

    main(args)
